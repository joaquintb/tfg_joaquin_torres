{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# from scipy.integrate import solve_ivp\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import tqdm as tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solving Classical LK 2D system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LV(x,a,b,c,d):    \n",
    "    xdot = np.array([a*x[0] - b*x[0]*x[1], d*x[0]*x[1] - c*x[1]])\n",
    "    return xdot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RK4(f, x0, t0, tf, dt):\n",
    "    \n",
    "    t = np.arange(t0, tf, dt)\n",
    "    nt = t.size\n",
    "    \n",
    "    nx = x0.size\n",
    "    x = np.zeros((nx,nt))\n",
    "    \n",
    "    x[:,0] = x0\n",
    "    \n",
    "    for k in range(nt-1):\n",
    "        k1 = dt*f(t[k], x[:,k])\n",
    "        k2 = dt*f(t[k] + dt/2, x[:,k] + k1/2)\n",
    "        k3 = dt*f(t[k] + dt/2, x[:,k] + k2/2)\n",
    "        k4 = dt*f(t[k] + dt, x[:,k] + k3)\n",
    "        \n",
    "        dx=(k1 + 2*k2 + 2*k3 +k4)/6\n",
    "        x[:,k+1] = x[:,k] + dx;  \n",
    "    \n",
    "    return x, t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the problem\n",
    "a = 1\n",
    "b = 1\n",
    "c = 1\n",
    "d = 1\n",
    "\n",
    "f= lambda t,x : LV(x,a,b,c,d)         # lambda is an anonymous function which can take may inputs but returns one output. Same case is with MATLAB denoted by @.\n",
    "x0 = np.array([0.5,1])                 # initial condition    \n",
    "\n",
    "# Solving the problem\n",
    "t0 = 0                                # time unit is second\n",
    "tf = 15\n",
    "num_points = 1000\n",
    "dt = (tf - t0) / (num_points - 1)\n",
    "x, t = RK4(f, x0, t0, tf, dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the solution\n",
    "plt.plot(t, x[0], label='Prey')\n",
    "plt.plot(t, x[1], label='Predator')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Population')\n",
    "plt.title('Lotka-Volterra Predator-Prey Model')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generating Observational Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_indices = np.random.choice(len(t), size=50, replace=False)\n",
    "\n",
    "x_obs = [x[0][ind] for ind in random_indices]\n",
    "y_obs = [x[1][ind] for ind in random_indices]\n",
    "\n",
    "# Generate Gaussian noise for x_obs and y_obs\n",
    "noise_x = 0.04 * np.random.randn(len(x_obs))\n",
    "noise_y = 0.04 * np.random.randn(len(y_obs))\n",
    "\n",
    "# Add the noise to the observed values\n",
    "x_obs_noise = [x_obs[ind] + noise_x[ind] for ind in range(len(x_obs))]\n",
    "y_obs_noise = [y_obs[ind] + noise_y[ind] for ind in range(len(y_obs))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.title(\"Noisy observational data\")\n",
    "plt.scatter([t[ind] for ind in random_indices], x_obs_noise)\n",
    "plt.scatter([t[ind] for ind in random_indices], y_obs_noise)\n",
    "plt.plot(t, x[0], label='Exact Prey', color=\"tab:grey\")\n",
    "plt.plot(t, x[1], label='Exact Predator', color=\"tab:grey\")\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Population')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_obs = torch.tensor([t[ind] for ind in random_indices], dtype=torch.float32).view(-1,1)\n",
    "u_obs_x = torch.tensor(x_obs,  dtype=torch.float32).view(-1,1) # Noise?\n",
    "u_obs_y = torch.tensor(y_obs,  dtype=torch.float32).view(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 30 approx. equally spaced points for training \n",
    "t_physics = []\n",
    "for i in range(1000):\n",
    "    if i % 34 == 0:\n",
    "        t_physics.append(t[i])\n",
    "t_physics = torch.tensor(t_physics, dtype=torch.float32).view(-1,1).requires_grad_(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 300 approx. equally spaced points for testing \n",
    "t_test = []\n",
    "u_test_x = []\n",
    "u_test_y = []\n",
    "for i in range(999):\n",
    "    if i % 3 == 0:\n",
    "        u_test_x.append(x[0][i])\n",
    "        u_test_y.append(x[1][i])\n",
    "        t_test.append(t[i])\n",
    "t_test = torch.tensor(t_test, dtype=torch.float32).view(-1,1).requires_grad_(True)\n",
    "u_test_x = torch.tensor(u_test_x, dtype=torch.float32).view(-1,1)\n",
    "u_test_y = torch.tensor(u_test_y, dtype=torch.float32).view(-1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining the Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FCN(nn.Module):\n",
    "    \"Defines a standard fully-connected network in PyTorch with sinusoidal activation\"\n",
    "    def __init__(self, N_INPUT, N_OUTPUT, N_HIDDEN, N_LAYERS):\n",
    "        super().__init__()\n",
    "        activation = nn.Tanh\n",
    "        self.fcs = nn.Sequential(*[\n",
    "                        nn.Linear(N_INPUT, N_HIDDEN),\n",
    "                        activation()])\n",
    "        self.fch = nn.Sequential(*[\n",
    "                        nn.Sequential(*[\n",
    "                            nn.Linear(N_HIDDEN, N_HIDDEN),\n",
    "                            activation()]) for _ in range(N_LAYERS-1)])\n",
    "        self.fce_predator = nn.Linear(N_HIDDEN, N_OUTPUT)\n",
    "        self.fce_prey = nn.Linear(N_HIDDEN, N_OUTPUT)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fcs(x)\n",
    "        x = self.fch(x)\n",
    "        prey_output = self.fce_prey(x)\n",
    "        predator_output = self.fce_predator(x)\n",
    "        return prey_output, predator_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the PINN to learn a parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a neural network to train\n",
    "pinn = FCN(1,1,32,3)\n",
    "\n",
    "# LEARNABLE PARAMS\n",
    "a = torch.nn.Parameter(torch.zeros(1, requires_grad=True))\n",
    "a_s = []\n",
    "b = torch.nn.Parameter(torch.zeros(1, requires_grad=True))\n",
    "b_s = []\n",
    "c = torch.nn.Parameter(torch.zeros(1, requires_grad=True))\n",
    "c_s = []\n",
    "d = torch.nn.Parameter(torch.zeros(1, requires_grad=True))\n",
    "d_s = []\n",
    "\n",
    "# Add a to the optimiser\n",
    "optimiser = torch.optim.Adam(list(pinn.parameters())+[a,b,c,d],lr=1e-3)\n",
    "\n",
    "# Initialize lists to store loss values\n",
    "physics_loss_values = []\n",
    "data_loss_values = []\n",
    "total_loss_values = []\n",
    "\n",
    "for i in tqdm.tqdm(range(12501)):\n",
    "    optimiser.zero_grad()\n",
    "\n",
    "    # Hyperparameter\n",
    "    lambda1 = 1e5\n",
    "\n",
    "    # -----------------------\n",
    "    #       PHYSICS LOSS\n",
    "    # -----------------------\n",
    "    u1,u2 = pinn(t_physics)\n",
    "\n",
    "    # Compute the derivatives with respect to time\n",
    "    du1dt = torch.autograd.grad(u1, t_physics, torch.ones_like(u1), create_graph=True)[0]\n",
    "    du2dt = torch.autograd.grad(u2, t_physics, torch.ones_like(u2), create_graph=True)[0]\n",
    "\n",
    "    # Compute the physics loss for Lotka-Volterra equations\n",
    "    phy_loss_x = torch.mean((du1dt - a*u1 + b*u1*u2) ** 2)\n",
    "    phy_loss_y = torch.mean((du2dt + c*u2 - d*u1*u2) ** 2)\n",
    "    total_physics_loss = phy_loss_x + phy_loss_y\n",
    "\n",
    "    # -----------------------\n",
    "    #       DATA LOSS\n",
    "    # -----------------------\n",
    "    # Compute the PINN output\n",
    "    u1, u2 = pinn(t_obs)\n",
    "    # Compute the data loss for the first equation (x)\n",
    "    data_loss_x = torch.mean((u1 - u_obs_x)**2)\n",
    "    # Compute the data loss for the second equation (y)\n",
    "    data_loss_y = torch.mean((u2 - u_obs_y)**2)\n",
    "\n",
    "    total_data_loss = data_loss_x + data_loss_y\n",
    "\n",
    "    # Backpropagate joint loss, take optimiser step\n",
    "    loss = total_physics_loss + lambda1*total_data_loss\n",
    "    loss.backward()\n",
    "    optimiser.step()\n",
    "\n",
    "    # Append loss values to lists\n",
    "    physics_loss_values.append(total_physics_loss.item())\n",
    "    data_loss_values.append(total_data_loss.item())\n",
    "    total_loss_values.append(loss.item())\n",
    "\n",
    "    # Keep track of parameter values\n",
    "    a_s.append(a.item())\n",
    "    b_s.append(b.item())\n",
    "    c_s.append(c.item())\n",
    "    d_s.append(d.item())\n",
    "\n",
    "    # plot the result as training progresses\n",
    "    if i % 5000 == 0: \n",
    "        u1, u2 = pinn(t_test)\n",
    "        with torch.no_grad():\n",
    "            plt.scatter(t_obs, u_obs_x, label=\"Noisy observations X\", alpha=0.3)\n",
    "            plt.scatter(t_obs, u_obs_y, label=\"Noisy observations Y\", alpha=0.3)\n",
    "            plt.plot(t_test, u1, label=\"PINN solution X\", color=\"tab:green\")\n",
    "            plt.plot(t_test, u2, label=\"PINN solution Y\", color=\"tab:blue\")  \n",
    "            plt.title(f\"Training step {i}\")\n",
    "            plt.legend()\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute model predictions\n",
    "with torch.no_grad():\n",
    "    u1_pred, u2_pred = pinn(t_test)\n",
    "\n",
    "# Compute MSE between model predictions and exact solution\n",
    "mse_u1 = torch.mean((u1_pred - u_test_x)**2).item()\n",
    "mse_u2 = torch.mean((u2_pred - u_test_y)**2).item()\n",
    "\n",
    "print(f\"MSE for u1: {mse_u1}\")\n",
    "print(f\"MSE for u2: {mse_u2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot loss values over time\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(range(12501), physics_loss_values, label='Physics Loss')\n",
    "plt.plot(range(12501), data_loss_values, label='Data Loss')\n",
    "plt.plot(range(12501), total_loss_values, label='Total Loss')\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss Function Over Time')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.title(\"Parameter a\")\n",
    "plt.plot(a_s, label=\"PINN estimate\")\n",
    "plt.hlines(1, 0, len(a_s), label=\"True value\", color=\"tab:green\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"Training step\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.title(\"Parameter b\")\n",
    "plt.plot(b_s, label=\"PINN estimate\")\n",
    "plt.hlines(1, 0, len(b_s), label=\"True value\", color=\"tab:green\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"Training step\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.title(\"Parameter c\")\n",
    "plt.plot(c_s, label=\"PINN estimate\")\n",
    "plt.hlines(1, 0, len(c_s), label=\"True value\", color=\"tab:green\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"Training step\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.title(\"Parameter d\")\n",
    "plt.plot(d_s, label=\"PINN estimate\")\n",
    "plt.hlines(1, 0, len(d_s), label=\"True value\", color=\"tab:green\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"Training step\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(a,b,c,d)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
